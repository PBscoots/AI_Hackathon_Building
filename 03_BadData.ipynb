{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_stuff(load_path, save_path): \n",
    "    df=pd.read_csv(load_path, sep=',',header=[0,1,2], encoding='iso-8859-1')\n",
    "    df.columns = df.columns.droplevel(level=[0, 2])\n",
    "\n",
    "    def timestamp(x):\n",
    "        i = x.replace(\" CEST\",'').strip()\n",
    "        i = i.replace(\"CET\",'').strip()\n",
    "        t = datetime.strptime(i, '%d-%b-%y %I:%M:%S %p')\n",
    "        t = (t - t.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "        return t/86400\n",
    "\n",
    "    def weekday(x): \n",
    "        i = x.replace(\" CEST\",'').strip()\n",
    "        i = i.replace(\"CET\",'').strip()\n",
    "        t = datetime.strptime(i, '%d-%b-%y %I:%M:%S %p')\n",
    "        return t.weekday() / 6\n",
    "\n",
    "    df1 = df\n",
    "    df1 = df1.drop(df.index[252566:])\n",
    "    df1 = df1.drop(df.index[:49643])\n",
    "    df1.index = pd.RangeIndex(len(df1.index))\n",
    "    df1 = df1.replace(r'\\s*Keine Anforderung\\s*', 0,regex=True)\n",
    "    df1 = df1.replace(r'\\s*keine Daten verfÃ¼gbar\\s*', 0,regex=True)\n",
    "    df1 = df1.replace(r'\\s*Anforderung\\s*', 1,regex=True)\n",
    "    df1 = df1.replace('NaN*', np.nan, regex=True)\n",
    "    df1 = df1.replace('nan*', np.nan, regex=True)\n",
    "    df1.iloc[0,15] = \"1.0\"\n",
    "    df1 = df1.fillna(method='ffill')\n",
    "    \n",
    "    # add day of week\n",
    "    df1['Weekday'] = df1.iloc[:, 0].apply(weekday)\n",
    "\n",
    "    # DONT LOOK AT IT!\n",
    "    df1.iloc[:, 1:14] = df1.iloc[:, 1:14].apply(pd.to_numeric)\n",
    "    df1.iloc[1:, 1] = df1.iloc[1:, 1] | df1.iloc[1:, 2]\n",
    "    df1.iloc[1:, 3] = df1.iloc[1:, 3] | df1.iloc[1:, 4]\n",
    "    df1.iloc[1:, 5] = df1.iloc[1:, 5] | df1.iloc[1:, 6]\n",
    "    df1.iloc[1:, 7] = df1.iloc[1:, 7] | df1.iloc[1:, 8]\n",
    "    df1.iloc[1:, 9] = df1.iloc[1:, 9] | df1.iloc[1:, 10]\n",
    "    df1.iloc[1:, 11] = df1.iloc[1:, 11] | df1.iloc[1:, 12]\n",
    "    df1.iloc[1:, 13] = df1.iloc[1:, 13] | df1.iloc[1:, 14]\n",
    "    df1 = df1.drop(df.columns[[2,4,6,8,10,12,14]],axis=1)\n",
    "    df1.iloc[:,0] = df1.iloc[:,0].apply(timestamp,)\n",
    "    df1.columns = [\"Timestamp\",\"3\",\"4\",\"5\",\"6\",\"7\",\"2\",\"1\",\"Floor\",\"Cycles\", 'Weekday']\n",
    "    df1 = df1[[\"Timestamp\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"Floor\",\"Cycles\", 'Weekday']]\n",
    "\n",
    "    # add directions\n",
    "    directions = [0]\n",
    "    for index, row in df1.iterrows():\n",
    "        if index == 0:\n",
    "            continue\n",
    "        direction = float(df1.loc[index, 'Floor']) - float(df1.loc[index - 1, 'Floor'])\n",
    "        directions.append(direction)\n",
    "\n",
    "    directions = np.sign(directions)\n",
    "    \n",
    "    df2 = df1\n",
    "    df2['Direction'] = directions\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing_stuff('./data/TrainingdataElevator.csv', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_label_stuff(df):\n",
    "    df = df.copy()\n",
    "    last_stop = 0\n",
    "\n",
    "    # make it deterministic\n",
    "    random.seed(43)\n",
    "\n",
    "    # probability prediction for the poor\n",
    "    # 25% percent that there is a request\n",
    "    prop = [0, 0, 0, 1]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index == (df.shape[0]-1): \n",
    "            break\n",
    "        # stopped or changed direction\n",
    "        if ((row[-1] == 0.0) & (row[-1] != df.iloc[index + 1, -1])) | ((row[-1] != 0.0) & ((row[-1] + df.iloc[index + 1, -1]) == 0.0)): \n",
    "            current_floor = float(row[8].strip())\n",
    "\n",
    "            # 1.0 is parking spot, only assign request for propability\n",
    "            if current_floor == 1.0: \n",
    "                # make a prediction \n",
    "                draw = random.choice(prop)\n",
    "                # print(f'index: {index}, draw: {draw}')\n",
    "                if draw == 0: \n",
    "                    continue\n",
    "\n",
    "            df.iloc[last_stop, int(current_floor)] = 1\n",
    "\n",
    "            # print(f'index: {index}, floor: {current_floor}')\n",
    "            last_stop = index\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = fill_missing_label_stuff(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_stuff(df, save_path):\n",
    "    # generate labels\n",
    "    df4 = df.copy()\n",
    "    last_index = 0\n",
    "    queue = np.array([[0, 0]])\n",
    "    ttl = 5\n",
    "\n",
    "    labels = np.array([])\n",
    "\n",
    "    for index, row in df4.iterrows():\n",
    "        if index == 0: \n",
    "            continue\n",
    "\n",
    "        # new request\n",
    "        if np.sum(row[1:8]) > 0: \n",
    "            idx = np.array(np.where(row[1:8] > 0)).ravel() + 1\n",
    "            #print(f'Req: {idx}, Row: {index}')\n",
    "            for id in idx: \n",
    "                # check if req is already queued\n",
    "                duplicate = np.where(queue[:, 0] == id)\n",
    "                \n",
    "                if np.array(duplicate).size == 0: \n",
    "                    queue = np.append(queue, np.array([[id, ttl]]), axis=0)\n",
    "                else: \n",
    "                    queue[duplicate, 1] = ttl\n",
    "\n",
    "        # stopped \n",
    "        if (row[-1] == 0.0) & (row[-1] != df4.iloc[index-1, -1]): \n",
    "            # decrease ttl \n",
    "            queue[:, 1] -= 1\n",
    "\n",
    "            # check for matches\n",
    "            current_floor = row[8]\n",
    "            match = np.where(queue[:ttl, 0] ==float(current_floor.strip()))\n",
    "            #print(f'Match: {queue[match]}, Row: {index}')\n",
    "\n",
    "\n",
    "            # \n",
    "            if np.array(match).size > 0: \n",
    "                #print(f'Label: {np.full((index - last_index), queue[match, 0])}, Match: {queue[match, 0]}')\n",
    "                labels = np.append(labels, np.full((index - last_index), queue[match, 0]), axis=0)\n",
    "                last_index = index\n",
    "            \n",
    "            # delete if match or ttl is zero\n",
    "            queue = np.delete(queue, match, axis=0)\n",
    "            queue = np.delete(queue, np.where(queue[:, 1] < 0), axis=0)\n",
    "\n",
    "    df_labels = pd.DataFrame(labels)\n",
    "    df_labels.to_csv('./' + ''.join(save_path.split('.')[:-1]) + '_label.csv', index=False)\n",
    "    \n",
    "    # normalize floor\n",
    "    df4.loc[:, 'Floor'] = (df4.loc[:, 'Floor'].astype(float) - 1.0) / 6.0\n",
    "      \n",
    "    # onehot encoding\n",
    "    encoder = OneHotEncoder(categories=[[1., 2., 3., 4., 5., 6., 7.]], sparse=False)\n",
    "    df_oh = pd.DataFrame(encoder.fit_transform(df_labels))\n",
    "\n",
    "    df_oh.to_csv('./' + ''.join(save_path.split('.')[:-1]) + '_label_oh.csv', index=False)\n",
    "    df4.to_csv(save_path, index=False)\n",
    "\n",
    "    return df4[:df_labels.shape[0]], df_labels, df_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, y_train_oh = generate_label_stuff(df1, './data/mid_part.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittensorflowcpu37conda6aabfcf6e13b4347a579e402e629d10b",
   "display_name": "Python 3.7.7 64-bit ('tensorflow_cpu37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}